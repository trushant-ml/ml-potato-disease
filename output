C:\Users\trush\AppData\Local\Programs\Python\Python39\python.exe C:\Users\trush\PycharmProjects\codebasic\potato-disease.py 
2025-04-27 19:20:25.257536: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-27 19:20:29.924184: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Found 2152 files belonging to 3 classes.
2025-04-27 19:20:39.472554: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow version: 2.19.0
['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']
68
(32, 256, 256, 3)
[0 0 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 0 1 2 1 0 0 0 1 1 2 2]
2025-04-27 19:20:39.966002: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2025-04-27 19:20:41.140379: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
54.400000000000006
6.800000000000001
C:\Users\trush\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\src\layers\convolutional\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Model: "sequential_2"
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ sequential (Sequential)         │ (32, 256, 256, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ sequential_1 (Sequential)       │ (32, 256, 256, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (32, 254, 254, 32)     │           896 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d (MaxPooling2D)    │ (32, 127, 127, 32)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_1 (Conv2D)               │ (32, 125, 125, 64)     │        18,496 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_1 (MaxPooling2D)  │ (32, 62, 62, 64)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_2 (Conv2D)               │ (32, 60, 60, 64)       │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_2 (MaxPooling2D)  │ (32, 30, 30, 64)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_3 (Conv2D)               │ (32, 28, 28, 64)       │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_3 (MaxPooling2D)  │ (32, 14, 14, 64)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_4 (Conv2D)               │ (32, 12, 12, 64)       │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_4 (MaxPooling2D)  │ (32, 6, 6, 64)         │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_5 (Conv2D)               │ (32, 4, 4, 64)         │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_5 (MaxPooling2D)  │ (32, 2, 2, 64)         │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten (Flatten)               │ (32, 256)              │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (32, 64)               │        16,448 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (32, 3)                │           195 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 183,747 (717.76 KB)
 Trainable params: 183,747 (717.76 KB)
 Non-trainable params: 0 (0.00 B)
None
Epoch 1/50
2025-04-27 19:20:51.718640: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 25165952 bytes after encountering the first element of size 25165952 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size
54/54 ━━━━━━━━━━━━━━━━━━━━ 63s 887ms/step - accuracy: 0.4753 - loss: 0.9461 - val_accuracy: 0.6198 - val_loss: 0.9266
Epoch 2/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 41s 760ms/step - accuracy: 0.7142 - loss: 0.6239 - val_accuracy: 0.8021 - val_loss: 0.4243
Epoch 3/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 735ms/step - accuracy: 0.8602 - loss: 0.3588 - val_accuracy: 0.8333 - val_loss: 0.4087
Epoch 4/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 731ms/step - accuracy: 0.8849 - loss: 0.3033 - val_accuracy: 0.8542 - val_loss: 0.3027
Epoch 5/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 732ms/step - accuracy: 0.9094 - loss: 0.2303 - val_accuracy: 0.8958 - val_loss: 0.3139
Epoch 6/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 733ms/step - accuracy: 0.9152 - loss: 0.2263 - val_accuracy: 0.9583 - val_loss: 0.1217
Epoch 7/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 736ms/step - accuracy: 0.9576 - loss: 0.1100 - val_accuracy: 0.9427 - val_loss: 0.1242
Epoch 8/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 729ms/step - accuracy: 0.9550 - loss: 0.1122 - val_accuracy: 0.8802 - val_loss: 0.2759
Epoch 9/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 728ms/step - accuracy: 0.9701 - loss: 0.0850 - val_accuracy: 0.8854 - val_loss: 0.2475
Epoch 10/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 722ms/step - accuracy: 0.9693 - loss: 0.1022 - val_accuracy: 0.9688 - val_loss: 0.0983
Epoch 11/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 725ms/step - accuracy: 0.9785 - loss: 0.0713 - val_accuracy: 0.9167 - val_loss: 0.2385
Epoch 12/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 742ms/step - accuracy: 0.9636 - loss: 0.0798 - val_accuracy: 0.9062 - val_loss: 0.2627
Epoch 13/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 731ms/step - accuracy: 0.9710 - loss: 0.0758 - val_accuracy: 0.8750 - val_loss: 0.2748
Epoch 14/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 739ms/step - accuracy: 0.9642 - loss: 0.0771 - val_accuracy: 0.8906 - val_loss: 0.3527
Epoch 15/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 736ms/step - accuracy: 0.9759 - loss: 0.0655 - val_accuracy: 0.8906 - val_loss: 0.2527
Epoch 16/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 724ms/step - accuracy: 0.9797 - loss: 0.0504 - val_accuracy: 0.9740 - val_loss: 0.0721
Epoch 17/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 41s 759ms/step - accuracy: 0.9761 - loss: 0.0567 - val_accuracy: 0.9740 - val_loss: 0.0457
Epoch 18/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 743ms/step - accuracy: 0.9814 - loss: 0.0541 - val_accuracy: 0.9792 - val_loss: 0.0486
Epoch 19/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 726ms/step - accuracy: 0.9919 - loss: 0.0261 - val_accuracy: 0.9062 - val_loss: 0.2965
Epoch 20/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 718ms/step - accuracy: 0.9789 - loss: 0.0614 - val_accuracy: 0.9740 - val_loss: 0.0773
Epoch 21/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 733ms/step - accuracy: 0.9888 - loss: 0.0317 - val_accuracy: 0.9219 - val_loss: 0.2663
Epoch 22/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 728ms/step - accuracy: 0.9739 - loss: 0.0799 - val_accuracy: 0.9479 - val_loss: 0.1119
Epoch 23/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 727ms/step - accuracy: 0.9869 - loss: 0.0392 - val_accuracy: 0.9323 - val_loss: 0.1356
Epoch 24/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 719ms/step - accuracy: 0.9961 - loss: 0.0168 - val_accuracy: 0.9635 - val_loss: 0.1008
Epoch 25/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 722ms/step - accuracy: 0.9948 - loss: 0.0184 - val_accuracy: 0.9844 - val_loss: 0.0406
Epoch 26/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 719ms/step - accuracy: 0.9888 - loss: 0.0349 - val_accuracy: 0.9479 - val_loss: 0.1399
Epoch 27/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 738ms/step - accuracy: 0.9773 - loss: 0.0629 - val_accuracy: 0.9844 - val_loss: 0.0615
Epoch 28/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 731ms/step - accuracy: 0.9914 - loss: 0.0301 - val_accuracy: 0.9740 - val_loss: 0.0559
Epoch 29/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 728ms/step - accuracy: 0.9954 - loss: 0.0189 - val_accuracy: 0.8229 - val_loss: 0.7660
Epoch 30/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 729ms/step - accuracy: 0.9858 - loss: 0.0343 - val_accuracy: 0.9271 - val_loss: 0.2307
Epoch 31/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 739ms/step - accuracy: 0.9902 - loss: 0.0328 - val_accuracy: 0.8854 - val_loss: 0.3308
Epoch 32/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 724ms/step - accuracy: 0.9804 - loss: 0.0504 - val_accuracy: 0.9688 - val_loss: 0.0707
Epoch 33/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 724ms/step - accuracy: 0.9934 - loss: 0.0236 - val_accuracy: 0.8594 - val_loss: 0.3938
Epoch 34/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 721ms/step - accuracy: 0.9811 - loss: 0.0455 - val_accuracy: 0.9531 - val_loss: 0.1222
Epoch 35/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 719ms/step - accuracy: 0.9936 - loss: 0.0225 - val_accuracy: 0.9844 - val_loss: 0.0652
Epoch 36/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 722ms/step - accuracy: 0.9957 - loss: 0.0153 - val_accuracy: 0.9635 - val_loss: 0.1432
Epoch 37/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 728ms/step - accuracy: 0.9770 - loss: 0.0690 - val_accuracy: 0.9479 - val_loss: 0.1676
Epoch 38/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 742ms/step - accuracy: 0.9815 - loss: 0.0495 - val_accuracy: 0.9844 - val_loss: 0.0424
Epoch 39/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 42s 770ms/step - accuracy: 0.9925 - loss: 0.0235 - val_accuracy: 0.9219 - val_loss: 0.1929
Epoch 40/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 41s 761ms/step - accuracy: 0.9939 - loss: 0.0172 - val_accuracy: 1.0000 - val_loss: 0.0092
Epoch 41/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 734ms/step - accuracy: 0.9894 - loss: 0.0332 - val_accuracy: 0.9844 - val_loss: 0.0245
Epoch 42/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 736ms/step - accuracy: 0.9951 - loss: 0.0132 - val_accuracy: 0.8906 - val_loss: 0.3271
Epoch 43/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 732ms/step - accuracy: 0.9919 - loss: 0.0273 - val_accuracy: 0.9896 - val_loss: 0.0244
Epoch 44/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 748ms/step - accuracy: 0.9975 - loss: 0.0110 - val_accuracy: 0.9896 - val_loss: 0.0296
Epoch 45/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 41s 756ms/step - accuracy: 0.9897 - loss: 0.0262 - val_accuracy: 0.9583 - val_loss: 0.0790
Epoch 46/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 738ms/step - accuracy: 0.9914 - loss: 0.0212 - val_accuracy: 0.9948 - val_loss: 0.0176
Epoch 47/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 734ms/step - accuracy: 0.9949 - loss: 0.0137 - val_accuracy: 0.9844 - val_loss: 0.0294
Epoch 48/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 40s 737ms/step - accuracy: 0.9878 - loss: 0.0361 - val_accuracy: 0.9792 - val_loss: 0.0747
Epoch 49/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 730ms/step - accuracy: 0.9954 - loss: 0.0183 - val_accuracy: 0.9896 - val_loss: 0.0361
Epoch 50/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 726ms/step - accuracy: 0.9922 - loss: 0.0211 - val_accuracy: 0.9740 - val_loss: 0.0605
8/8 ━━━━━━━━━━━━━━━━━━━━ 5s 214ms/step - accuracy: 0.9951 - loss: 0.0165
Scores  [0.022832345217466354, 0.9921875]
{'verbose': 1, 'epochs': 50, 'steps': 54}
dict_keys(['verbose', 'epochs', 'steps'])
[0.5266203880310059, 0.7708333134651184, 0.8512731194496155, 0.8877314925193787, 0.9033564925193787, 0.9247685074806213, 0.9542824029922485, 0.9496527910232544, 0.9652777910232544, 0.9681712985038757, 0.9785879850387573, 0.9733796119689941, 0.9646990895271301, 0.9756944179534912, 0.9704861044883728, 0.9768518805503845, 0.9791666865348816, 0.9791666865348816, 0.9849537014961243, 0.9837962985038757, 0.9861111044883728, 0.9814814925193787, 0.9907407164573669, 0.9947916865348816, 0.9924768805503845, 0.9728009104728699, 0.9837962985038757, 0.9913194179534912, 0.9936342835426331, 0.9855324029922485, 0.9820601940155029, 0.9855324029922485, 0.9907407164573669, 0.9832175970077515, 0.9942129850387573, 0.9913194179534912, 0.9826388955116272, 0.9803240895271301, 0.9884259104728699, 0.9907407164573669, 0.9930555820465088, 0.9959490895271301, 0.9890046119689941, 0.9965277910232544, 0.9866898059844971, 0.9924768805503845, 0.9947916865348816, 0.9866898059844971, 0.9953703880310059, 0.9907407164573669]
Traceback (most recent call last):
  File "C:\Users\trush\PycharmProjects\codebasic\potato-disease.py", line 155, in <module>
    dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
NameError: name 'dict_keys' is not defined

Process finished with exit code 1
