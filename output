C:\Users\trush\AppData\Local\Programs\Python\Python39\python.exe C:\Users\trush\PycharmProjects\codebasic\potato-disease.py 
2025-04-28 22:26:57.272591: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-28 22:27:01.622532: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Found 2152 files belonging to 3 classes.
2025-04-28 22:27:13.389251: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow version: 2.19.0
['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']
68
2025-04-28 22:27:13.953377: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
(32, 256, 256, 3)
[0 0 0 1 2 0 2 2 0 1 1 1 1 1 2 1 1 1 0 1 1 0 0 2 0 1 0 0 0 0 1 0]
54.400000000000006
2025-04-28 22:27:15.611993: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
6.800000000000001
C:\Users\trush\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\src\layers\convolutional\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Model: "sequential_2"
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ sequential (Sequential)         │ (32, 256, 256, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ sequential_1 (Sequential)       │ (32, 256, 256, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (32, 254, 254, 32)     │           896 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d (MaxPooling2D)    │ (32, 127, 127, 32)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_1 (Conv2D)               │ (32, 125, 125, 64)     │        18,496 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_1 (MaxPooling2D)  │ (32, 62, 62, 64)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_2 (Conv2D)               │ (32, 60, 60, 64)       │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_2 (MaxPooling2D)  │ (32, 30, 30, 64)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_3 (Conv2D)               │ (32, 28, 28, 64)       │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_3 (MaxPooling2D)  │ (32, 14, 14, 64)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_4 (Conv2D)               │ (32, 12, 12, 64)       │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_4 (MaxPooling2D)  │ (32, 6, 6, 64)         │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_5 (Conv2D)               │ (32, 4, 4, 64)         │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_5 (MaxPooling2D)  │ (32, 2, 2, 64)         │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten (Flatten)               │ (32, 256)              │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (32, 64)               │        16,448 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (32, 3)                │           195 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 183,747 (717.76 KB)
 Trainable params: 183,747 (717.76 KB)
 Non-trainable params: 0 (0.00 B)
None
Epoch 1/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 57s 806ms/step - accuracy: 0.4891 - loss: 0.9451 - val_accuracy: 0.4323 - val_loss: 0.8712
Epoch 2/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 71s 1s/step - accuracy: 0.5689 - loss: 0.8033 - val_accuracy: 0.8229 - val_loss: 0.4808
Epoch 3/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 90s 2s/step - accuracy: 0.7957 - loss: 0.4676 - val_accuracy: 0.8073 - val_loss: 0.4101
Epoch 4/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 94s 2s/step - accuracy: 0.8722 - loss: 0.3200 - val_accuracy: 0.8698 - val_loss: 0.2909
Epoch 5/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 91s 2s/step - accuracy: 0.8819 - loss: 0.2876 - val_accuracy: 0.8073 - val_loss: 0.4486
Epoch 6/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 88s 2s/step - accuracy: 0.8698 - loss: 0.3238 - val_accuracy: 0.9427 - val_loss: 0.1681
Epoch 7/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 90s 2s/step - accuracy: 0.9126 - loss: 0.2296 - val_accuracy: 0.9688 - val_loss: 0.0965
Epoch 8/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 368s 1s/step - accuracy: 0.9433 - loss: 0.1421 - val_accuracy: 0.7396 - val_loss: 0.5837
Epoch 9/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 730ms/step - accuracy: 0.9312 - loss: 0.1828 - val_accuracy: 0.9844 - val_loss: 0.0816
Epoch 10/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 38s 706ms/step - accuracy: 0.9669 - loss: 0.0960 - val_accuracy: 0.9583 - val_loss: 0.1199
Epoch 11/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 38s 709ms/step - accuracy: 0.9488 - loss: 0.1301 - val_accuracy: 0.8594 - val_loss: 0.2765
Epoch 12/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 962s 18s/step - accuracy: 0.9715 - loss: 0.0696 - val_accuracy: 0.4583 - val_loss: 1.6353
Epoch 13/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 93s 2s/step - accuracy: 0.7632 - loss: 0.5631 - val_accuracy: 0.9740 - val_loss: 0.1183
Epoch 14/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 96s 2s/step - accuracy: 0.9231 - loss: 0.1834 - val_accuracy: 0.9688 - val_loss: 0.0566
Epoch 15/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 49s 907ms/step - accuracy: 0.9478 - loss: 0.1599 - val_accuracy: 0.9219 - val_loss: 0.1685
Epoch 16/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 45s 825ms/step - accuracy: 0.9737 - loss: 0.0743 - val_accuracy: 0.9167 - val_loss: 0.1674
Epoch 17/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 44s 817ms/step - accuracy: 0.9791 - loss: 0.0561 - val_accuracy: 0.9479 - val_loss: 0.1407
Epoch 18/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 53s 978ms/step - accuracy: 0.9777 - loss: 0.0550 - val_accuracy: 0.8073 - val_loss: 0.4386
Epoch 19/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 88s 2s/step - accuracy: 0.9743 - loss: 0.0643 - val_accuracy: 0.9896 - val_loss: 0.0403
Epoch 20/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 85s 2s/step - accuracy: 0.9835 - loss: 0.0503 - val_accuracy: 0.9531 - val_loss: 0.1121
Epoch 21/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 89s 2s/step - accuracy: 0.9813 - loss: 0.0450 - val_accuracy: 0.9844 - val_loss: 0.0458
Epoch 22/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 90s 2s/step - accuracy: 0.9415 - loss: 0.1844 - val_accuracy: 0.9427 - val_loss: 0.1484
Epoch 23/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 85s 2s/step - accuracy: 0.9763 - loss: 0.0624 - val_accuracy: 0.8906 - val_loss: 0.2804
Epoch 24/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 83s 2s/step - accuracy: 0.9807 - loss: 0.0490 - val_accuracy: 0.9792 - val_loss: 0.0558
Epoch 25/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 90s 2s/step - accuracy: 0.9795 - loss: 0.0522 - val_accuracy: 0.9844 - val_loss: 0.0316
Epoch 26/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 89s 2s/step - accuracy: 0.9896 - loss: 0.0340 - val_accuracy: 0.9583 - val_loss: 0.0951
Epoch 27/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 93s 2s/step - accuracy: 0.9870 - loss: 0.0314 - val_accuracy: 0.9427 - val_loss: 0.1669
Epoch 28/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 505s 9s/step - accuracy: 0.9891 - loss: 0.0285 - val_accuracy: 0.9896 - val_loss: 0.0198
Epoch 29/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 49s 896ms/step - accuracy: 0.9797 - loss: 0.0496 - val_accuracy: 0.9792 - val_loss: 0.0473
Epoch 30/50
2025-04-28 23:29:48.996518: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 25165952 bytes after encountering the first element of size 25165952 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size
54/54 ━━━━━━━━━━━━━━━━━━━━ 44s 808ms/step - accuracy: 0.9647 - loss: 0.1010 - val_accuracy: 0.7969 - val_loss: 0.5883
Epoch 31/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 50s 926ms/step - accuracy: 0.9861 - loss: 0.0437 - val_accuracy: 0.9844 - val_loss: 0.0621
Epoch 32/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 725ms/step - accuracy: 0.9935 - loss: 0.0205 - val_accuracy: 0.9792 - val_loss: 0.0719
Epoch 33/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 39s 730ms/step - accuracy: 0.9788 - loss: 0.0632 - val_accuracy: 0.9792 - val_loss: 0.0572
Epoch 34/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 41s 766ms/step - accuracy: 0.9911 - loss: 0.0253 - val_accuracy: 0.8802 - val_loss: 0.2902
Epoch 35/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 46s 837ms/step - accuracy: 0.9811 - loss: 0.0594 - val_accuracy: 0.9740 - val_loss: 0.0565
Epoch 36/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 43s 796ms/step - accuracy: 0.9900 - loss: 0.0244 - val_accuracy: 1.0000 - val_loss: 0.0055
Epoch 37/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 44s 808ms/step - accuracy: 0.9801 - loss: 0.0587 - val_accuracy: 0.9271 - val_loss: 0.1837
Epoch 38/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 44s 820ms/step - accuracy: 0.9808 - loss: 0.0439 - val_accuracy: 0.9844 - val_loss: 0.0507
Epoch 39/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 49s 903ms/step - accuracy: 0.9941 - loss: 0.0176 - val_accuracy: 0.9792 - val_loss: 0.0536
Epoch 40/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 48s 895ms/step - accuracy: 0.9986 - loss: 0.0091 - val_accuracy: 0.9792 - val_loss: 0.0337
Epoch 41/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 45s 840ms/step - accuracy: 0.9943 - loss: 0.0125 - val_accuracy: 0.9219 - val_loss: 0.2148
Epoch 42/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 45s 827ms/step - accuracy: 0.9893 - loss: 0.0196 - val_accuracy: 0.9948 - val_loss: 0.0461
Epoch 43/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 44s 824ms/step - accuracy: 0.9987 - loss: 0.0093 - val_accuracy: 0.9062 - val_loss: 0.2725
Epoch 44/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 43s 806ms/step - accuracy: 0.9697 - loss: 0.0856 - val_accuracy: 0.9792 - val_loss: 0.0555
Epoch 45/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 41s 767ms/step - accuracy: 0.9781 - loss: 0.0525 - val_accuracy: 0.9896 - val_loss: 0.0261
Epoch 46/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 42s 775ms/step - accuracy: 0.9914 - loss: 0.0199 - val_accuracy: 0.9948 - val_loss: 0.0157
Epoch 47/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 42s 778ms/step - accuracy: 0.9919 - loss: 0.0205 - val_accuracy: 1.0000 - val_loss: 0.0049
Epoch 48/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 49s 904ms/step - accuracy: 0.9949 - loss: 0.0132 - val_accuracy: 0.9062 - val_loss: 0.2118
Epoch 49/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 43s 796ms/step - accuracy: 0.9799 - loss: 0.0508 - val_accuracy: 0.9792 - val_loss: 0.0594
Epoch 50/50
54/54 ━━━━━━━━━━━━━━━━━━━━ 42s 781ms/step - accuracy: 0.9803 - loss: 0.0497 - val_accuracy: 0.9948 - val_loss: 0.0429
8/8 ━━━━━━━━━━━━━━━━━━━━ 7s 283ms/step - accuracy: 0.9634 - loss: 0.0920
Scores  [0.11351779103279114, 0.9609375]
{'verbose': 1, 'epochs': 50, 'steps': 54}
dict_keys(['verbose', 'epochs', 'steps'])
[0.49016204476356506, 0.6365740895271301, 0.8130787014961243, 0.8518518805503845, 0.8859953880310059, 0.8854166865348816, 0.9172453880310059, 0.9363425970077515, 0.9415509104728699, 0.9565972089767456, 0.9508101940155029, 0.9583333134651184, 0.8229166865348816, 0.9461805820465088, 0.9583333134651184, 0.9699074029922485, 0.9751157164573669, 0.9756944179534912, 0.9745370149612427, 0.9814814925193787, 0.9832175970077515, 0.9496527910232544, 0.9722222089767456, 0.9814814925193787, 0.9739583134651184, 0.9913194179534912, 0.9849537014961243, 0.9907407164573669, 0.9797453880310059, 0.9641203880310059, 0.9907407164573669, 0.9872685074806213, 0.9832175970077515, 0.9890046119689941, 0.9861111044883728, 0.9907407164573669, 0.9814814925193787, 0.9814814925193787, 0.9947916865348816, 0.9982638955116272, 0.9890046119689941, 0.9936342835426331, 0.9965277910232544, 0.9606481194496155, 0.9809027910232544, 0.9901620149612427, 0.9953703880310059, 0.9924768805503845, 0.9803240895271301, 0.9861111044883728]
First image to predict
First image actual label:  Potato___Early_blight
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 467ms/step
predicted label: [1.0000000e+00 4.7951514e-09 5.3788080e-26]
Traceback (most recent call last):
  File "C:\Users\trush\PycharmProjects\codebasic\potato-disease.py", line 188, in <module>
    print("predicted label:", class_names[np.argmax(batch_prediction[0])]) # its array and we meed max probablility
NameError: name 'np' is not defined

Process finished with exit code 1
